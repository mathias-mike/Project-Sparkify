{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Sparkify\n",
    "Sparkify is a music streaming startup with an impressive userbase growth _(their marketing team must be doing one hell of a job)_ and is looking to move their processes and data to the cloud. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.\n",
    "\n",
    "I am tasked with building a data warehouse for the analytics team, I will basically build an ETL pipeline that extracts their data from S3, stages them in Redshift, and transform the data into a set of dimensional tables for their analytics team to continue finding insights in what songs their users are listening to.\n",
    "\n",
    "Let's get to work:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# First things first, we have to create a redshift cluster for our project on AWS\r\n",
    "# Here, we'd be using IaC to proceed with the processes\r\n",
    "\r\n",
    "# importing boto3, AWS python SDK\r\n",
    "import boto3\r\n",
    "\r\n",
    "import configparser\r\n",
    "import json\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Extracting config variables \r\n",
    "config = configparser.ConfigParser()\r\n",
    "config.read_file(open('dwh.cfg'))\r\n",
    "\r\n",
    "KEY = config.get('USER', 'KEY')\r\n",
    "SECRET = config.get('USER', 'SECRET')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "DWH_ROLE_NAME = config.get('CLUSTER', 'DWH_ROLE_NAME')\r\n",
    "DWH_DB_NAME = config.get('CLUSTER', 'DWH_DB_NAME')\r\n",
    "DWH_CLUSTER_ID = config.get('CLUSTER', 'DWH_CLUSTER_ID')\r\n",
    "DWH_NODE_TYPE = config.get('CLUSTER', 'DWH_NODE_TYPE')\r\n",
    "DWH_USER_NAME = config.get('CLUSTER', 'DWH_USER_NAME')\r\n",
    "DWH_USER_PASSWORD = config.get('CLUSTER', 'DWH_USER_PASSWORD')\r\n",
    "DWH_NUMBER_0F_NODES = int(config.get('CLUSTER', 'DWH_NUMBER_0F_NODES'))\r\n",
    "\r\n",
    "variables = pd.DataFrame({\r\n",
    "    'keys':['DWH_ROLE_NAME', 'DWH_DB_NAME', 'DWH_CLUSTER_ID', 'DWH_NODE_TYPE', 'DWH_NUMBER_0F_NODES'], \r\n",
    "    'values':[DWH_ROLE_NAME, DWH_DB_NAME, DWH_CLUSTER_ID, DWH_NODE_TYPE, DWH_NUMBER_0F_NODES]\r\n",
    "})\r\n",
    "\r\n",
    "variables"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  keys                values\n",
       "0        DWH_ROLE_NAME  redshift_s3_readonly\n",
       "1          DWH_DB_NAME            sparkifydb\n",
       "2       DWH_CLUSTER_ID      sparkify-cluster\n",
       "3        DWH_NODE_TYPE             dc2.large\n",
       "4  DWH_NUMBER_0F_NODES                     4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_ROLE_NAME</td>\n",
       "      <td>redshift_s3_readonly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_DB_NAME</td>\n",
       "      <td>sparkifydb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_CLUSTER_ID</td>\n",
       "      <td>sparkify-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_NUMBER_0F_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Next we create an IAM role for our redshift clust with AmazonS3ReadOnlyAccess permision\r\n",
    "iam = boto3.client('iam', region_name='us-east-2', aws_access_key_id=KEY, aws_secret_access_key=SECRET)\r\n",
    "\r\n",
    "try:\r\n",
    "    print('Creating IAM role for Redshift cluster...')\r\n",
    "    iam_role = iam.create_role(\r\n",
    "        RoleName=DWH_ROLE_NAME,\r\n",
    "        AssumeRolePolicyDocument=json.dumps({\r\n",
    "            'Statement': [{\r\n",
    "                'Action': 'sts:AssumeRole',\r\n",
    "                'Effect': 'Allow',\r\n",
    "                'Principal': {'Service': 'redshift.amazonaws.com'}\r\n",
    "            }],\r\n",
    "            'Version': '2012-10-17'\r\n",
    "        }),\r\n",
    "        Description='Allows Redshift cluster to call AWS services on you behalf',\r\n",
    "    )\r\n",
    "    print('Role creation successful!')\r\n",
    "except Exception as e:\r\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating IAM role for Redshift cluster...\n",
      "Role creation successful!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "iam.attach_role_policy(\r\n",
    "    RoleName=DWH_ROLE_NAME,\r\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\r\n",
    ")['ResponseMetadata']['HTTPStatusCode']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "role_arn = iam_role['Role']['Arn']\r\n",
    "role_arn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Now we build the redshift cluster\r\n",
    "redshift = boto3.client('redshift', region_name='us-east-2', aws_access_key_id=KEY, aws_secret_access_key=SECRET)\r\n",
    "\r\n",
    "try:\r\n",
    "    print('Creating Redshift cluster...')\r\n",
    "    redshift_cluster = redshift.create_cluster(\r\n",
    "        DBName=DWH_DB_NAME,\r\n",
    "        ClusterIdentifier=DWH_CLUSTER_ID,\r\n",
    "        NodeType=DWH_NODE_TYPE,\r\n",
    "        MasterUsername=DWH_USER_NAME,\r\n",
    "        MasterUserPassword=DWH_USER_PASSWORD,\r\n",
    "        NumberOfNodes=DWH_NUMBER_0F_NODES,\r\n",
    "        IamRoles=[\r\n",
    "            role_arn,\r\n",
    "        ]\r\n",
    "    )\r\n",
    "    print('Redshift cluster creation successful!')\r\n",
    "except Exception as e:\r\n",
    "    print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Checking cluster availability status\r\n",
    "cluster_props = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_ID)['Clusters'][0]\r\n",
    "cluster_props['ClusterAvailabilityStatus']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "response = redshift.delete_cluster(ClusterIdentifier=DWH_CLUSTER_ID, SkipFinalClusterSnapshot=True)\r\n",
    "response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('data': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "c7c2a41b292db013da2e0f9f93aefcc7908094ade4156cf1b2ccc35683197532"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}