{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Sparkify Control Point"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# First things first, we have to create a redshift cluster for our project on AWS\r\n",
    "# Here, we'd be using IaC to proceed with the processes\r\n",
    "\r\n",
    "# importing boto3, AWS python SDK\r\n",
    "import boto3\r\n",
    "from botocore.exceptions import ClientError\r\n",
    "\r\n",
    "import configparser\r\n",
    "import json\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Extracting config variables \r\n",
    "config = configparser.ConfigParser()\r\n",
    "config.read_file(open('dwh.cfg'))\r\n",
    "\r\n",
    "KEY = config.get('USER', 'KEY')\r\n",
    "SECRET = config.get('USER', 'SECRET')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "DWH_ROLE_NAME = config.get('CLUSTER', 'DWH_ROLE_NAME')\r\n",
    "DWH_DB_NAME = config.get('CLUSTER', 'DWH_DB_NAME')\r\n",
    "DWH_CLUSTER_ID = config.get('CLUSTER', 'DWH_CLUSTER_ID')\r\n",
    "DWH_NODE_TYPE = config.get('CLUSTER', 'DWH_NODE_TYPE')\r\n",
    "DWH_USER_NAME = config.get('CLUSTER', 'DWH_USER_NAME')\r\n",
    "DWH_USER_PASSWORD = config.get('CLUSTER', 'DWH_USER_PASSWORD')\r\n",
    "DWH_NUMBER_0F_NODES = int(config.get('CLUSTER', 'DWH_NUMBER_0F_NODES'))\r\n",
    "DWH_PORT = int(config.get('CLUSTER', 'DWH_PORT'))\r\n",
    "\r\n",
    "variables = pd.DataFrame({\r\n",
    "    'keys':['DWH_ROLE_NAME', 'DWH_DB_NAME', 'DWH_CLUSTER_ID', 'DWH_NODE_TYPE', 'DWH_NUMBER_0F_NODES', 'DWH_PORT'], \r\n",
    "    'values':[DWH_ROLE_NAME, DWH_DB_NAME, DWH_CLUSTER_ID, DWH_NODE_TYPE, DWH_NUMBER_0F_NODES, DWH_PORT]\r\n",
    "})\r\n",
    "\r\n",
    "variables"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  keys                values\n",
       "0        DWH_ROLE_NAME  redshift_s3_readonly\n",
       "1          DWH_DB_NAME            sparkifydb\n",
       "2       DWH_CLUSTER_ID      sparkify-cluster\n",
       "3        DWH_NODE_TYPE             dc2.large\n",
       "4  DWH_NUMBER_0F_NODES                     4\n",
       "5             DWH_PORT                  5439"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_ROLE_NAME</td>\n",
       "      <td>redshift_s3_readonly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_DB_NAME</td>\n",
       "      <td>sparkifydb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_CLUSTER_ID</td>\n",
       "      <td>sparkify-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_NUMBER_0F_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create IAM role for Redshift cluster\n",
    "This role will grant redshift AmazonS3ReadOnlyAccess"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Instantiating IAM client\r\n",
    "iam = boto3.client('iam', region_name='us-east-2', aws_access_key_id=KEY, aws_secret_access_key=SECRET)\r\n",
    "\r\n",
    "try:\r\n",
    "    print('Creating IAM role for Redshift cluster...')\r\n",
    "    iam_role = iam.create_role(\r\n",
    "        RoleName=DWH_ROLE_NAME,\r\n",
    "        AssumeRolePolicyDocument=json.dumps({\r\n",
    "            'Statement': [{\r\n",
    "                'Action': 'sts:AssumeRole',\r\n",
    "                'Effect': 'Allow',\r\n",
    "                'Principal': {'Service': 'redshift.amazonaws.com'}\r\n",
    "            }],\r\n",
    "            'Version': '2012-10-17'\r\n",
    "        }),\r\n",
    "        Description='Allows Redshift cluster to call AWS services on you behalf',\r\n",
    "    )\r\n",
    "    print('Role creation successful!')\r\n",
    "    \r\n",
    "    \r\n",
    "    iam.attach_role_policy(\r\n",
    "        RoleName=DWH_ROLE_NAME,\r\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\r\n",
    "    )['ResponseMetadata']['HTTPStatusCode']\r\n",
    "    \r\n",
    "    print('Role policy attached successfully!')\r\n",
    "except Exception as e:\r\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\r\n",
    "        iam_role = iam.get_role(RoleName=DWH_ROLE_NAME)\r\n",
    "        print('Role gotten')\r\n",
    "    else:\r\n",
    "        print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating IAM role for Redshift cluster...\n",
      "Role gotten\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "role_arn = iam_role['Role']['Arn']\r\n",
    "role_arn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build the Redshift cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Instantiating redshift client\r\n",
    "redshift = boto3.client('redshift', region_name='us-east-2', aws_access_key_id=KEY, aws_secret_access_key=SECRET)\r\n",
    "\r\n",
    "try:\r\n",
    "    print('Creating Redshift cluster...')\r\n",
    "    redshift_cluster = redshift.create_cluster(\r\n",
    "        DBName=DWH_DB_NAME,\r\n",
    "        ClusterIdentifier=DWH_CLUSTER_ID,\r\n",
    "        NodeType=DWH_NODE_TYPE,\r\n",
    "        MasterUsername=DWH_USER_NAME,\r\n",
    "        MasterUserPassword=DWH_USER_PASSWORD,\r\n",
    "        NumberOfNodes=DWH_NUMBER_0F_NODES,\r\n",
    "        IamRoles=[\r\n",
    "            role_arn,\r\n",
    "        ]\r\n",
    "    )\r\n",
    "    print('Redshift cluster creation successful!')\r\n",
    "except Exception as e:\r\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Redshift cluster...\n",
      "Redshift cluster creation successful!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Checking cluster availability status\r\n",
    "cluster_props = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_ID)['Clusters'][0]\r\n",
    "cluster_props['ClusterAvailabilityStatus']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Available'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Obtaining cluster endpoint\r\n",
    "DWH_ENDPOINT = cluster_props['Endpoint']['Address']\r\n",
    "DWH_PORT = int(cluster_props['Endpoint']['Port'])\r\n",
    "print('Endpoint: {}\\nPort: {}'.format(DWH_ENDPOINT, DWH_PORT))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# cluster_vars = pd.DataFrame({\r\n",
    "#     'keys':['ClusterIdentifier', 'NodeType', 'ClusterStatus', 'Endpoint:Address', 'Endpoint:Port', 'IamRole', 'Vpc', 'NumberOfNodes'], \r\n",
    "#     'values':[cluster_props['ClusterIdentifier'], cluster_props['NodeType'], cluster_props['ClusterStatus'], \r\n",
    "#               cluster_props['Endpoint']['Address'], cluster_props['Endpoint']['Port'], cluster_props['IamRoles'][0]['IamRoleArn'],\r\n",
    "#               cluster_props['VpcId'], cluster_props['NumberOfNodes']]\r\n",
    "# })\r\n",
    "\r\n",
    "# cluster_vars"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open Incomming TCP port to access the cluster endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# get an ec2 resourse\r\n",
    "ec2 = boto3.resource('ec2', region_name='us-east-2', aws_access_key_id=KEY, aws_secret_access_key=SECRET)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "try: \r\n",
    "    vpc = ec2.Vpc(id=cluster_props['VpcId'])\r\n",
    "    default_sg = list(vpc.security_groups.all())[0]\r\n",
    "    print(default_sg)\r\n",
    "    \r\n",
    "    default_sg.authorize_ingress(\r\n",
    "        GroupName=default_sg.group_name,\r\n",
    "        CidrIp='0.0.0.0/0',\r\n",
    "        IpProtocol='TCP',\r\n",
    "        FromPort=DWH_PORT,\r\n",
    "        ToPort=DWH_PORT\r\n",
    "    )\r\n",
    "except Exception as e:\r\n",
    "    print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning UP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# response = redshift.delete_cluster(ClusterIdentifier=DWH_CLUSTER_ID, SkipFinalClusterSnapshot=True)\r\n",
    "# response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# iam.detach_role_policy(RoleName=DWH_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\r\n",
    "# iam.delete_role(RoleName=DWH_ROLE_NAME)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('data': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "c7c2a41b292db013da2e0f9f93aefcc7908094ade4156cf1b2ccc35683197532"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}